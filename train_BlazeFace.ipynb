{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import stuff\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from itertools import product as product\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Function\n",
    "import pandas as pd\n",
    "\n",
    "# import dataset\n",
    "from utils.dataset import VOCDataset, DatasetTransform, make_datapath_list, Anno_xml2list, od_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dirs\n",
    "os.makedirs(\"weights\", exist_ok=True)\n",
    "os.makedirs(\"log\", exist_ok=True)\n",
    "input_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "# Blazeface channels\n",
    "channels = 64\n",
    "\"\"\"\n",
    "The original blazeface use channels=24. \n",
    "However, it was not enough to detect persons in our dataset.\n",
    "Since detecting faces are quite a simple task compared to person detection, fewer channels were enabled.\n",
    "\"\"\"\n",
    "\n",
    "# Use focal loss or not\n",
    "focal = False\n",
    "\n",
    "# Use centernet-like Blazeface\n",
    "center = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set up person only VOC dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val not found\n",
      "trainlist:  6469\n",
      "vallist:  2097\n"
     ]
    }
   ],
   "source": [
    "# load files\n",
    "vocpath = os.path.join(\"..\", \"VOCdevkit\", \"VOC2007\")\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(vocpath, cls=\"person\")\n",
    "\n",
    "# extend with VOC2012\n",
    "vocpath = \"../VOCdevkit/VOC2012\"\n",
    "train_img_list2, train_anno_list2, _, _ = make_datapath_list(vocpath, cls=\"person\", VOC2012=True)\n",
    "\n",
    "train_img_list.extend(train_img_list2)\n",
    "train_anno_list.extend(train_anno_list2)\n",
    "\n",
    "# make Dataset\n",
    "voc_classes = ['person']\n",
    "color_mean = (104, 117, 123)  # (BGR)の色の平均値\n",
    "\n",
    "print(\"trainlist: \", len(train_img_list))\n",
    "print(\"vallist: \", len(val_img_list))\n",
    "\n",
    "## DatasetTransformを適応\n",
    "transform = DatasetTransform(input_size, color_mean)\n",
    "transform_anno = Anno_xml2list(voc_classes)\n",
    "\n",
    "train_dataset = VOCDataset(train_img_list, train_anno_list, phase = \"train\", transform=transform, transform_anno = transform_anno)\n",
    "val_dataset = VOCDataset(val_img_list, val_anno_list, phase=\"val\", transform=DatasetTransform(\n",
    "    input_size, color_mean), transform_anno=Anno_xml2list(voc_classes))\n",
    "\n",
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "val_dataloader = data.DataLoader(\n",
    "    val_dataset, batch_size=batch_size, shuffle=False, collate_fn=od_collate_fn, num_workers=8)\n",
    "\n",
    "dataloaders_dict = {\"train\": train_dataloader, \"val\": val_dataloader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 3, 128, 128])\n",
      "32\n",
      "torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "# check operation\n",
    "batch_iterator = iter(dataloaders_dict[\"train\"])  # iter\n",
    "images, targets = next(batch_iterator)  # get first element\n",
    "print(images.size())  # torch.Size([4, 3, 300, 300])\n",
    "print(len(targets))\n",
    "print(targets[1].shape)  # check targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4453, 0.4589, 0.8464, 1.0000, 0.0000],\n",
       "        [0.4453, 0.5749, 0.6536, 1.0000, 0.0000],\n",
       "        [0.8151, 0.7198, 0.8932, 0.9614, 0.0000]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test with ssd model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if input_size==256:\n",
    "    from utils.blazeface import SSD256 as SSD\n",
    "    ssd_cfg = {\n",
    "        'num_classes': 2,  # 背景クラスを含めた合計クラス数\n",
    "        'input_size': input_size,  # 画像の入力サイズ\n",
    "        'bbox_aspect_num': [4, 6],  # 出力するDBoxのアスペクト比の種類\n",
    "        'feature_maps': [16, 8],  # 各sourceの画像サイズ\n",
    "        'steps': [8, 16],  # DBOXの大きさを決める\n",
    "        'min_sizes': [16, 32],  # DBOXの大きさを決める\n",
    "        'max_sizes': [32, 100],  # DBOXの大きさを決める\n",
    "        'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "    }\n",
    "elif input_size==128:\n",
    "    from utils.blazeface import SSD\n",
    "    ssd_cfg = {\n",
    "        'num_classes': 2,  # 背景クラスを含めた合計クラス数\n",
    "        'input_size': 128,  # 画像の入力サイズ\n",
    "        'bbox_aspect_num': [4, 6],  # 出力するDBoxのアスペクト比の種類\n",
    "        'feature_maps': [16, 8],  # 各sourceの画像サイズ\n",
    "        'steps': [4, 8],  # DBOXの大きさを決める\n",
    "        'min_sizes': [30, 60],  # DBOXの大きさを決める\n",
    "        'max_sizes': [60, 128],  # DBOXの大きさを決める\n",
    "        'aspect_ratios': [[2], [2, 3], [2, 3], [2, 3], [2], [2]],\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using: cuda:0\n",
      "set weights!\n"
     ]
    }
   ],
   "source": [
    "net = SSD(phase=\"train\", cfg=ssd_cfg, channels=channels)\n",
    "\n",
    "# SSDのweightsを設定\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        init.kaiming_normal_(m.weight.data)\n",
    "        if m.bias is not None:\n",
    "            nn.init.constant_(m.bias, 0.0)\n",
    "\n",
    "# set inits for loc and conf\n",
    "net.loc.apply(weights_init)\n",
    "net.conf.apply(weights_init)\n",
    "\n",
    "# GPUが使えるか確認\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"using:\", device)\n",
    "\n",
    "print(\"set weights!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSD(\n",
      "  (blaze): BlazeFace(\n",
      "    (features): Sequential(\n",
      "      (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (4): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (5): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=64)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (6): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (7): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=128)\n",
      "          (2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (8): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=128)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (9): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (10): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (extra): BlazeFaceExtra(\n",
      "    (features): Sequential(\n",
      "      (0): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=256)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (mp): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (1): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): BlazeBlock(\n",
      "        (conv1): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=256)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv2): Sequential(\n",
      "          (0): ReLU(inplace=True)\n",
      "          (1): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=64)\n",
      "          (2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (loc): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (conf): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Conv2d(256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Conv2d(256, 12, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.ssd_model import MultiBoxLoss\n",
    "\n",
    "# define loss\n",
    "criterion = MultiBoxLoss(jaccard_thresh=0.5,neg_pos=3, device=device, focal=focal)\n",
    "\n",
    "# optim\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_lr(epoch):\n",
    "    lr = 1e-4\n",
    "    for i,lr_decay_epoch in enumerate([80,120]):\n",
    "        if epoch >= lr_decay_epoch:\n",
    "            lr *= 0.1\n",
    "    return lr\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    lr = get_current_lr(epoch)\n",
    "    print(\"lr is:\", lr)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルを学習させる関数を作成\n",
    "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
    "\n",
    "    # GPUが使えるかを確認\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"used device：\", device)\n",
    "\n",
    "    # ネットワークをGPUへ\n",
    "    net.to(device)\n",
    "\n",
    "    # ネットワークがある程度固定であれば、高速化させる\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "    # イテレーションカウンタをセット\n",
    "    iteration = 1\n",
    "    epoch_train_loss = 0.0  # epochの損失和\n",
    "    epoch_val_loss = 0.0  # epochの損失和\n",
    "    logs = []\n",
    "\n",
    "    # epochのループ\n",
    "    for epoch in range(num_epochs+1):\n",
    "        \n",
    "        adjust_learning_rate(optimizer, epoch)\n",
    "        \n",
    "        # 開始時刻を保存\n",
    "        t_epoch_start = time.time()\n",
    "        t_iter_start = time.time()\n",
    "\n",
    "        print('-------------')\n",
    "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
    "        print('-------------')\n",
    "\n",
    "        # epochごとの訓練と検証のループ\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                net.train()  # モデルを訓練モードに\n",
    "                print('train')\n",
    "            else:\n",
    "                if((epoch+1) % 5 == 0):\n",
    "                    net.eval()   # モデルを検証モードに\n",
    "                    print('-------------')\n",
    "                    print('val')\n",
    "                else:\n",
    "                    # 検証は5回に1回だけ行う\n",
    "                    continue\n",
    "\n",
    "            # データローダーからminibatchずつ取り出すループ\n",
    "            for images, targets in dataloaders_dict[phase]:\n",
    "\n",
    "                # GPUが使えるならGPUにデータを送る\n",
    "                images = images.to(device)\n",
    "                targets = [ann.to(device)\n",
    "                           for ann in targets]  # リストの各要素のテンソルをGPUへ\n",
    "\n",
    "                # optimizerを初期化\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # 順伝搬（forward）計算\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    # 順伝搬（forward）計算\n",
    "                    outputs = net(images)\n",
    "\n",
    "                    # 損失の計算\n",
    "                    loss_l, loss_c = criterion(outputs, targets)\n",
    "                    loss = loss_l + loss_c\n",
    "\n",
    "                    # 訓練時はバックプロパゲーション\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()  # 勾配の計算\n",
    "\n",
    "                        # 勾配が大きくなりすぎると計算が不安定になるので、clipで最大でも勾配2.0に留める\n",
    "                        nn.utils.clip_grad_value_(\n",
    "                            net.parameters(), clip_value=2.0)\n",
    "\n",
    "                        optimizer.step()  # パラメータ更新\n",
    "\n",
    "                        if (iteration % 10 == 0):  # 10iterに1度、lossを表示\n",
    "                            t_iter_finish = time.time()\n",
    "                            duration = t_iter_finish - t_iter_start\n",
    "                            print('Iteration {} || Loss: {:.4f} || 10iter: {:.4f} sec.'.format(\n",
    "                                iteration, loss.item(), duration))\n",
    "                            t_iter_start = time.time()\n",
    "\n",
    "                        epoch_train_loss += loss.item()\n",
    "                        iteration += 1\n",
    "\n",
    "                    # 検証時\n",
    "                    else:\n",
    "                        epoch_val_loss += loss.item()\n",
    "\n",
    "        # epochのphaseごとのlossと正解率\n",
    "        t_epoch_finish = time.time()\n",
    "        print('-------------')\n",
    "        print('epoch {} || Epoch_TRAIN_Loss:{:.4f} ||Epoch_VAL_Loss:{:.4f}'.format(\n",
    "            epoch+1, epoch_train_loss, epoch_val_loss))\n",
    "        print('timer:  {:.4f} sec.'.format(t_epoch_finish - t_epoch_start))\n",
    "        t_epoch_start = time.time()\n",
    "\n",
    "        # ログを保存\n",
    "        log_epoch = {'epoch': epoch+1,\n",
    "                     'train_loss': epoch_train_loss, 'val_loss': epoch_val_loss}\n",
    "        logs.append(log_epoch)\n",
    "        df = pd.DataFrame(logs)\n",
    "        df.to_csv(\"log/log_output.csv\")\n",
    "\n",
    "        epoch_train_loss = 0.0  # epochの損失和\n",
    "        epoch_val_loss = 0.0  # epochの損失和\n",
    "\n",
    "        # ネットワークを保存する\n",
    "        if ((epoch+1) % 10 == 0):\n",
    "            torch.save(net.state_dict(), 'weights/blazeface{}_'.format(input_size) +\n",
    "                       str(epoch+1) + '.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# start training here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "used device： cuda:0\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 1/150\n",
      "-------------\n",
      "train\n",
      "Iteration 10 || Loss: 22.5487 || 10iter: 7.5143 sec.\n",
      "Iteration 20 || Loss: 20.4253 || 10iter: 3.6372 sec.\n",
      "Iteration 30 || Loss: 18.7865 || 10iter: 3.7234 sec.\n",
      "Iteration 40 || Loss: 19.4787 || 10iter: 3.7046 sec.\n",
      "Iteration 50 || Loss: 16.7488 || 10iter: 3.6960 sec.\n",
      "Iteration 60 || Loss: 14.9106 || 10iter: 3.6627 sec.\n",
      "Iteration 70 || Loss: 16.1222 || 10iter: 3.6477 sec.\n",
      "Iteration 80 || Loss: 16.4054 || 10iter: 3.6974 sec.\n",
      "Iteration 90 || Loss: 15.2272 || 10iter: 3.6138 sec.\n",
      "Iteration 100 || Loss: 15.6662 || 10iter: 3.6454 sec.\n",
      "Iteration 110 || Loss: 15.4372 || 10iter: 3.7520 sec.\n",
      "Iteration 120 || Loss: 14.2358 || 10iter: 4.0816 sec.\n",
      "Iteration 130 || Loss: 14.4491 || 10iter: 4.0365 sec.\n",
      "Iteration 140 || Loss: 14.3126 || 10iter: 3.6645 sec.\n",
      "Iteration 150 || Loss: 19.1626 || 10iter: 3.7097 sec.\n",
      "Iteration 160 || Loss: 13.7796 || 10iter: 3.7511 sec.\n",
      "Iteration 170 || Loss: 17.5071 || 10iter: 3.7056 sec.\n",
      "Iteration 180 || Loss: 14.3437 || 10iter: 3.7253 sec.\n",
      "Iteration 190 || Loss: 13.6438 || 10iter: 3.5627 sec.\n",
      "Iteration 200 || Loss: 13.7172 || 10iter: 3.3501 sec.\n",
      "-------------\n",
      "epoch 1 || Epoch_TRAIN_Loss:3393.7682 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  79.1181 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 2/150\n",
      "-------------\n",
      "train\n",
      "Iteration 210 || Loss: 14.8495 || 10iter: 6.1780 sec.\n",
      "Iteration 220 || Loss: 12.7446 || 10iter: 3.7726 sec.\n",
      "Iteration 230 || Loss: 13.9678 || 10iter: 3.6722 sec.\n",
      "Iteration 240 || Loss: 11.8088 || 10iter: 3.6635 sec.\n",
      "Iteration 250 || Loss: 14.0492 || 10iter: 3.6833 sec.\n",
      "Iteration 260 || Loss: 14.0112 || 10iter: 3.6430 sec.\n",
      "Iteration 270 || Loss: 12.5184 || 10iter: 3.6438 sec.\n",
      "Iteration 280 || Loss: 16.5442 || 10iter: 3.7034 sec.\n",
      "Iteration 290 || Loss: 14.5278 || 10iter: 3.7049 sec.\n",
      "Iteration 300 || Loss: 12.3384 || 10iter: 3.7491 sec.\n",
      "Iteration 310 || Loss: 12.1479 || 10iter: 3.6433 sec.\n",
      "Iteration 320 || Loss: 12.1118 || 10iter: 3.7348 sec.\n",
      "Iteration 330 || Loss: 11.7679 || 10iter: 3.6941 sec.\n",
      "Iteration 340 || Loss: 12.6762 || 10iter: 3.7115 sec.\n",
      "Iteration 350 || Loss: 12.3955 || 10iter: 3.6919 sec.\n",
      "Iteration 360 || Loss: 10.7906 || 10iter: 3.6803 sec.\n",
      "Iteration 370 || Loss: 13.2989 || 10iter: 3.7497 sec.\n",
      "Iteration 380 || Loss: 12.7676 || 10iter: 3.6955 sec.\n",
      "Iteration 390 || Loss: 11.9035 || 10iter: 3.7472 sec.\n",
      "Iteration 400 || Loss: 11.0480 || 10iter: 3.3447 sec.\n",
      "-------------\n",
      "epoch 2 || Epoch_TRAIN_Loss:2660.4273 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  77.9275 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 3/150\n",
      "-------------\n",
      "train\n",
      "Iteration 410 || Loss: 13.6322 || 10iter: 4.7412 sec.\n",
      "Iteration 420 || Loss: 11.9111 || 10iter: 4.1115 sec.\n",
      "Iteration 430 || Loss: 12.1449 || 10iter: 3.7747 sec.\n",
      "Iteration 440 || Loss: 9.7894 || 10iter: 3.7494 sec.\n",
      "Iteration 450 || Loss: 12.3495 || 10iter: 3.7967 sec.\n",
      "Iteration 460 || Loss: 11.4153 || 10iter: 3.8357 sec.\n",
      "Iteration 470 || Loss: 10.4655 || 10iter: 3.6958 sec.\n",
      "Iteration 480 || Loss: 10.6566 || 10iter: 3.6921 sec.\n",
      "Iteration 490 || Loss: 10.9808 || 10iter: 3.6961 sec.\n",
      "Iteration 500 || Loss: 11.5464 || 10iter: 3.7421 sec.\n",
      "Iteration 510 || Loss: 11.5250 || 10iter: 3.6962 sec.\n",
      "Iteration 520 || Loss: 10.6723 || 10iter: 3.7027 sec.\n",
      "Iteration 530 || Loss: 11.7232 || 10iter: 3.7636 sec.\n",
      "Iteration 540 || Loss: 11.0821 || 10iter: 3.7532 sec.\n",
      "Iteration 550 || Loss: 10.3688 || 10iter: 3.7241 sec.\n",
      "Iteration 560 || Loss: 10.0894 || 10iter: 3.6858 sec.\n",
      "Iteration 570 || Loss: 12.0440 || 10iter: 3.7670 sec.\n",
      "Iteration 580 || Loss: 12.0366 || 10iter: 3.7261 sec.\n",
      "Iteration 590 || Loss: 10.9555 || 10iter: 4.1657 sec.\n",
      "Iteration 600 || Loss: 10.7895 || 10iter: 3.4877 sec.\n",
      "-------------\n",
      "epoch 3 || Epoch_TRAIN_Loss:2383.1194 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  79.1697 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 4/150\n",
      "-------------\n",
      "train\n",
      "Iteration 610 || Loss: 12.6594 || 10iter: 2.9424 sec.\n",
      "Iteration 620 || Loss: 11.7079 || 10iter: 4.7964 sec.\n",
      "Iteration 630 || Loss: 11.5099 || 10iter: 3.6256 sec.\n",
      "Iteration 640 || Loss: 9.7712 || 10iter: 3.7328 sec.\n",
      "Iteration 650 || Loss: 10.4589 || 10iter: 3.7103 sec.\n",
      "Iteration 660 || Loss: 11.5097 || 10iter: 3.6986 sec.\n",
      "Iteration 670 || Loss: 11.3667 || 10iter: 3.6695 sec.\n",
      "Iteration 680 || Loss: 11.2946 || 10iter: 3.6858 sec.\n",
      "Iteration 690 || Loss: 9.0729 || 10iter: 3.6735 sec.\n",
      "Iteration 700 || Loss: 9.3220 || 10iter: 3.6979 sec.\n",
      "Iteration 710 || Loss: 10.5712 || 10iter: 3.7310 sec.\n",
      "Iteration 720 || Loss: 10.2825 || 10iter: 3.7869 sec.\n",
      "Iteration 730 || Loss: 10.5675 || 10iter: 3.6866 sec.\n",
      "Iteration 740 || Loss: 9.2522 || 10iter: 3.7191 sec.\n",
      "Iteration 750 || Loss: 11.2401 || 10iter: 3.6745 sec.\n",
      "Iteration 760 || Loss: 10.1342 || 10iter: 3.6661 sec.\n",
      "Iteration 770 || Loss: 10.5420 || 10iter: 3.7038 sec.\n",
      "Iteration 780 || Loss: 8.0688 || 10iter: 3.6653 sec.\n",
      "Iteration 790 || Loss: 9.2815 || 10iter: 3.6615 sec.\n",
      "Iteration 800 || Loss: 9.8428 || 10iter: 3.5167 sec.\n",
      "Iteration 810 || Loss: 10.8593 || 10iter: 3.3968 sec.\n",
      "-------------\n",
      "epoch 4 || Epoch_TRAIN_Loss:2168.6042 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  77.9275 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 5/150\n",
      "-------------\n",
      "train\n",
      "Iteration 820 || Loss: 9.5277 || 10iter: 6.5565 sec.\n",
      "Iteration 830 || Loss: 10.5073 || 10iter: 3.8273 sec.\n",
      "Iteration 840 || Loss: 10.1626 || 10iter: 3.7588 sec.\n",
      "Iteration 850 || Loss: 10.3846 || 10iter: 3.6742 sec.\n",
      "Iteration 860 || Loss: 12.9533 || 10iter: 3.7828 sec.\n",
      "Iteration 870 || Loss: 10.2510 || 10iter: 3.6828 sec.\n",
      "Iteration 880 || Loss: 10.5014 || 10iter: 3.6816 sec.\n",
      "Iteration 890 || Loss: 9.8378 || 10iter: 3.6740 sec.\n",
      "Iteration 900 || Loss: 8.6193 || 10iter: 3.7278 sec.\n",
      "Iteration 910 || Loss: 10.4999 || 10iter: 3.7299 sec.\n",
      "Iteration 920 || Loss: 10.5771 || 10iter: 3.6672 sec.\n",
      "Iteration 930 || Loss: 8.9392 || 10iter: 3.7901 sec.\n",
      "Iteration 940 || Loss: 11.1137 || 10iter: 3.7390 sec.\n",
      "Iteration 950 || Loss: 10.5550 || 10iter: 3.6694 sec.\n",
      "Iteration 960 || Loss: 11.0979 || 10iter: 3.6734 sec.\n",
      "Iteration 970 || Loss: 10.6657 || 10iter: 3.6461 sec.\n",
      "Iteration 980 || Loss: 9.5648 || 10iter: 3.6849 sec.\n",
      "Iteration 990 || Loss: 9.9373 || 10iter: 3.6906 sec.\n",
      "Iteration 1000 || Loss: 10.3537 || 10iter: 3.7027 sec.\n",
      "Iteration 1010 || Loss: 10.3155 || 10iter: 3.4159 sec.\n",
      "-------------\n",
      "val\n",
      "-------------\n",
      "epoch 5 || Epoch_TRAIN_Loss:2034.5860 ||Epoch_VAL_Loss:675.7839\n",
      "timer:  89.4556 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 6/150\n",
      "-------------\n",
      "train\n",
      "Iteration 1020 || Loss: 8.5028 || 10iter: 5.5503 sec.\n",
      "Iteration 1030 || Loss: 9.7737 || 10iter: 4.3113 sec.\n",
      "Iteration 1040 || Loss: 10.8222 || 10iter: 3.7630 sec.\n",
      "Iteration 1050 || Loss: 9.7726 || 10iter: 3.7402 sec.\n",
      "Iteration 1060 || Loss: 9.3968 || 10iter: 3.7570 sec.\n",
      "Iteration 1070 || Loss: 8.4893 || 10iter: 3.6504 sec.\n",
      "Iteration 1080 || Loss: 8.9208 || 10iter: 3.6629 sec.\n",
      "Iteration 1090 || Loss: 10.5808 || 10iter: 3.6717 sec.\n",
      "Iteration 1100 || Loss: 9.4065 || 10iter: 3.6953 sec.\n",
      "Iteration 1110 || Loss: 8.2725 || 10iter: 3.7389 sec.\n",
      "Iteration 1120 || Loss: 9.0933 || 10iter: 3.7058 sec.\n",
      "Iteration 1130 || Loss: 8.4038 || 10iter: 3.7057 sec.\n",
      "Iteration 1140 || Loss: 9.7452 || 10iter: 3.6937 sec.\n",
      "Iteration 1150 || Loss: 8.1577 || 10iter: 3.6938 sec.\n",
      "Iteration 1160 || Loss: 9.1904 || 10iter: 3.6391 sec.\n",
      "Iteration 1170 || Loss: 9.8317 || 10iter: 3.6723 sec.\n",
      "Iteration 1180 || Loss: 9.3573 || 10iter: 3.7283 sec.\n",
      "Iteration 1190 || Loss: 8.0732 || 10iter: 3.7118 sec.\n",
      "Iteration 1200 || Loss: 8.1336 || 10iter: 3.7498 sec.\n",
      "Iteration 1210 || Loss: 8.5818 || 10iter: 3.4738 sec.\n",
      "-------------\n",
      "epoch 6 || Epoch_TRAIN_Loss:1908.5910 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  78.8586 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 7/150\n",
      "-------------\n",
      "train\n",
      "Iteration 1220 || Loss: 9.5252 || 10iter: 3.6545 sec.\n",
      "Iteration 1230 || Loss: 8.3581 || 10iter: 4.5701 sec.\n",
      "Iteration 1240 || Loss: 9.6602 || 10iter: 3.5936 sec.\n",
      "Iteration 1250 || Loss: 10.4722 || 10iter: 3.6871 sec.\n",
      "Iteration 1260 || Loss: 8.6971 || 10iter: 3.6595 sec.\n",
      "Iteration 1270 || Loss: 10.4249 || 10iter: 3.6253 sec.\n",
      "Iteration 1280 || Loss: 9.0668 || 10iter: 3.6783 sec.\n",
      "Iteration 1290 || Loss: 8.8525 || 10iter: 3.7130 sec.\n",
      "Iteration 1300 || Loss: 9.7897 || 10iter: 3.7114 sec.\n",
      "Iteration 1310 || Loss: 8.8281 || 10iter: 3.6472 sec.\n",
      "Iteration 1320 || Loss: 9.4618 || 10iter: 3.7294 sec.\n",
      "Iteration 1330 || Loss: 9.1377 || 10iter: 3.6430 sec.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1340 || Loss: 8.1670 || 10iter: 3.6865 sec.\n",
      "Iteration 1350 || Loss: 10.7478 || 10iter: 3.7634 sec.\n",
      "Iteration 1360 || Loss: 9.5503 || 10iter: 3.7305 sec.\n",
      "Iteration 1370 || Loss: 8.5046 || 10iter: 3.6910 sec.\n",
      "Iteration 1380 || Loss: 9.4814 || 10iter: 3.7139 sec.\n",
      "Iteration 1390 || Loss: 8.8221 || 10iter: 3.6337 sec.\n",
      "Iteration 1400 || Loss: 8.8724 || 10iter: 3.7073 sec.\n",
      "Iteration 1410 || Loss: 8.7612 || 10iter: 3.5459 sec.\n",
      "Iteration 1420 || Loss: 8.2808 || 10iter: 3.4160 sec.\n",
      "-------------\n",
      "epoch 7 || Epoch_TRAIN_Loss:1820.9165 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  77.9438 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 8/150\n",
      "-------------\n",
      "train\n",
      "Iteration 1430 || Loss: 9.0718 || 10iter: 6.7785 sec.\n",
      "Iteration 1440 || Loss: 10.1622 || 10iter: 3.7324 sec.\n",
      "Iteration 1450 || Loss: 9.8537 || 10iter: 3.7132 sec.\n",
      "Iteration 1460 || Loss: 8.3607 || 10iter: 3.6899 sec.\n",
      "Iteration 1470 || Loss: 8.3677 || 10iter: 3.7450 sec.\n",
      "Iteration 1480 || Loss: 8.2059 || 10iter: 3.6585 sec.\n",
      "Iteration 1490 || Loss: 11.7468 || 10iter: 4.0845 sec.\n",
      "Iteration 1500 || Loss: 8.5191 || 10iter: 3.6565 sec.\n",
      "Iteration 1510 || Loss: 7.5577 || 10iter: 3.6637 sec.\n",
      "Iteration 1520 || Loss: 8.8684 || 10iter: 3.7349 sec.\n",
      "Iteration 1530 || Loss: 8.2085 || 10iter: 3.7173 sec.\n",
      "Iteration 1540 || Loss: 8.3099 || 10iter: 3.7127 sec.\n",
      "Iteration 1550 || Loss: 8.6931 || 10iter: 3.6698 sec.\n",
      "Iteration 1560 || Loss: 9.0733 || 10iter: 3.6899 sec.\n",
      "Iteration 1570 || Loss: 8.2620 || 10iter: 3.6772 sec.\n",
      "Iteration 1580 || Loss: 7.8406 || 10iter: 3.6047 sec.\n",
      "Iteration 1590 || Loss: 7.9292 || 10iter: 3.6722 sec.\n",
      "Iteration 1600 || Loss: 8.1073 || 10iter: 3.6982 sec.\n",
      "Iteration 1610 || Loss: 7.3982 || 10iter: 3.6141 sec.\n",
      "Iteration 1620 || Loss: 8.2398 || 10iter: 3.4061 sec.\n",
      "-------------\n",
      "epoch 8 || Epoch_TRAIN_Loss:1737.4124 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  78.0914 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 9/150\n",
      "-------------\n",
      "train\n",
      "Iteration 1630 || Loss: 8.5099 || 10iter: 5.8363 sec.\n",
      "Iteration 1640 || Loss: 9.1940 || 10iter: 3.7257 sec.\n",
      "Iteration 1650 || Loss: 8.5753 || 10iter: 3.7745 sec.\n",
      "Iteration 1660 || Loss: 8.9083 || 10iter: 3.7956 sec.\n",
      "Iteration 1670 || Loss: 8.7264 || 10iter: 3.7007 sec.\n",
      "Iteration 1680 || Loss: 8.7676 || 10iter: 3.6787 sec.\n",
      "Iteration 1690 || Loss: 8.1691 || 10iter: 3.6930 sec.\n",
      "Iteration 1700 || Loss: 8.2775 || 10iter: 3.7067 sec.\n",
      "Iteration 1710 || Loss: 7.9014 || 10iter: 3.6625 sec.\n",
      "Iteration 1720 || Loss: 7.7835 || 10iter: 3.7828 sec.\n",
      "Iteration 1730 || Loss: 9.5028 || 10iter: 3.7257 sec.\n",
      "Iteration 1740 || Loss: 8.2347 || 10iter: 3.7808 sec.\n",
      "Iteration 1750 || Loss: 7.8091 || 10iter: 3.6795 sec.\n",
      "Iteration 1760 || Loss: 7.1864 || 10iter: 3.6891 sec.\n",
      "Iteration 1770 || Loss: 8.4940 || 10iter: 3.7631 sec.\n",
      "Iteration 1780 || Loss: 7.3133 || 10iter: 3.7215 sec.\n",
      "Iteration 1790 || Loss: 8.2673 || 10iter: 3.7223 sec.\n",
      "Iteration 1800 || Loss: 7.8582 || 10iter: 3.7609 sec.\n",
      "Iteration 1810 || Loss: 9.1774 || 10iter: 3.6832 sec.\n",
      "Iteration 1820 || Loss: 8.9593 || 10iter: 3.4278 sec.\n",
      "-------------\n",
      "epoch 9 || Epoch_TRAIN_Loss:1665.4210 ||Epoch_VAL_Loss:0.0000\n",
      "timer:  78.5051 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 10/150\n",
      "-------------\n",
      "train\n",
      "Iteration 1830 || Loss: 8.0980 || 10iter: 4.1657 sec.\n",
      "Iteration 1840 || Loss: 7.7851 || 10iter: 4.3428 sec.\n",
      "Iteration 1850 || Loss: 8.2199 || 10iter: 3.6944 sec.\n",
      "Iteration 1860 || Loss: 8.0817 || 10iter: 3.7193 sec.\n",
      "Iteration 1870 || Loss: 8.9930 || 10iter: 3.6679 sec.\n",
      "Iteration 1880 || Loss: 7.2181 || 10iter: 3.7269 sec.\n",
      "Iteration 1890 || Loss: 8.9111 || 10iter: 3.6812 sec.\n",
      "Iteration 1900 || Loss: 6.6686 || 10iter: 3.7001 sec.\n",
      "Iteration 1910 || Loss: 7.5189 || 10iter: 3.7102 sec.\n",
      "Iteration 1920 || Loss: 8.4194 || 10iter: 3.7463 sec.\n",
      "Iteration 1930 || Loss: 7.3692 || 10iter: 3.7276 sec.\n",
      "Iteration 1940 || Loss: 7.8322 || 10iter: 3.7035 sec.\n",
      "Iteration 1950 || Loss: 7.1636 || 10iter: 3.7540 sec.\n",
      "Iteration 1960 || Loss: 7.6693 || 10iter: 4.0963 sec.\n",
      "Iteration 1970 || Loss: 7.7333 || 10iter: 3.7092 sec.\n",
      "Iteration 1980 || Loss: 6.7248 || 10iter: 3.6745 sec.\n",
      "Iteration 1990 || Loss: 7.6229 || 10iter: 3.6751 sec.\n",
      "Iteration 2000 || Loss: 7.5608 || 10iter: 3.7621 sec.\n",
      "Iteration 2010 || Loss: 7.6534 || 10iter: 3.6767 sec.\n",
      "Iteration 2020 || Loss: 8.4941 || 10iter: 3.5377 sec.\n",
      "Iteration 2030 || Loss: 14.6393 || 10iter: 3.1410 sec.\n",
      "-------------\n",
      "val\n",
      "-------------\n",
      "epoch 10 || Epoch_TRAIN_Loss:1619.8951 ||Epoch_VAL_Loss:536.4415\n",
      "timer:  89.3801 sec.\n",
      "lr is: 0.0001\n",
      "-------------\n",
      "Epoch 11/150\n",
      "-------------\n",
      "train\n",
      "Iteration 2040 || Loss: 7.7393 || 10iter: 7.4414 sec.\n",
      "Iteration 2050 || Loss: 10.2427 || 10iter: 3.6015 sec.\n",
      "Iteration 2060 || Loss: 9.1427 || 10iter: 3.7351 sec.\n",
      "Iteration 2070 || Loss: 6.9870 || 10iter: 3.7013 sec.\n",
      "Iteration 2080 || Loss: 7.1127 || 10iter: 3.7384 sec.\n",
      "Iteration 2090 || Loss: 7.8186 || 10iter: 3.6646 sec.\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 150\n",
    "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
